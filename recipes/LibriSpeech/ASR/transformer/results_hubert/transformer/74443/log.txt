2024-02-01 21:01:28,832 - speechbrain.core - INFO - Beginning experiment!
2024-02-01 21:01:28,832 - speechbrain.core - INFO - Experiment folder: results/transformer/74443
2024-02-01 21:01:29,232 - speechbrain.utils.superpowers - DEBUG - Brotli @ file:///work/ci_py311/brotli-split_1676830125088/work
certifi @ file:///croot/certifi_1700501669400/work/certifi
cffi @ file:///croot/cffi_1700254295673/work
charset-normalizer @ file:///tmp/build/80754af9/charset-normalizer_1630003229654/work
cryptography @ file:///croot/cryptography_1702070282333/work
filelock @ file:///croot/filelock_1700591183607/work
fsspec==2023.12.2
gmpy2 @ file:///work/ci_py311/gmpy2_1676839849213/work
huggingface-hub==0.20.2
HyperPyYAML==1.2.2
idna @ file:///work/ci_py311/idna_1676822698822/work
Jinja2 @ file:///work/ci_py311/jinja2_1676823587943/work
joblib==1.3.2
MarkupSafe @ file:///croot/markupsafe_1704205993651/work
mkl-fft @ file:///croot/mkl_fft_1695058164594/work
mkl-random @ file:///croot/mkl_random_1695059800811/work
mkl-service==2.4.0
mpmath @ file:///croot/mpmath_1690848262763/work
networkx @ file:///croot/networkx_1690561992265/work
numpy @ file:///croot/numpy_and_numpy_base_1704311704800/work/dist/numpy-1.26.3-cp311-cp311-linux_x86_64.whl#sha256=10a078151ecec16bafb535f7487635217625fa06536dec8509e514648c78d626
packaging==23.2
Pillow @ file:///croot/pillow_1696580024257/work
pycparser @ file:///tmp/build/80754af9/pycparser_1636541352034/work
pyOpenSSL @ file:///croot/pyopenssl_1690223430423/work
PySocks @ file:///work/ci_py311/pysocks_1676822712504/work
PyYAML==6.0.1
regex==2023.12.25
requests @ file:///croot/requests_1690400202158/work
ruamel.yaml==0.18.5
ruamel.yaml.clib==0.2.8
safetensors==0.4.2
scipy==1.11.4
sentencepiece==0.1.99
# Editable install with no version control (speechbrain==0.5.16)
-e /home/rajivratn/satyam/speechbrain
sympy @ file:///croot/sympy_1701397643339/work
tokenizers==0.15.1
torch==2.0.1
torchaudio==2.0.2
torchvision==0.15.2
tqdm==4.66.1
transformers==4.37.1
triton==2.0.0
typing_extensions @ file:///croot/typing_extensions_1705005625920/work
urllib3 @ file:///croot/urllib3_1698257533958/work


2024-02-01 21:01:29,385 - librispeech_prepare - INFO - Data_preparation...
2024-02-01 21:01:29,950 - librispeech_prepare - INFO - Creating csv lists in  results/transformer/74443/train-clean-100.csv...
2024-02-01 21:01:38,741 - librispeech_prepare - INFO - results/transformer/74443/train-clean-100.csv successfully created!
2024-02-01 21:01:40,834 - librispeech_prepare - INFO - Creating csv lists in  results/transformer/74443/train-clean-360.csv...
2024-02-01 21:01:50,875 - librispeech_prepare - INFO - results/transformer/74443/train-clean-360.csv successfully created!
2024-02-01 21:01:53,940 - librispeech_prepare - INFO - Creating csv lists in  results/transformer/74443/train-other-500.csv...
2024-02-01 21:02:05,686 - librispeech_prepare - INFO - results/transformer/74443/train-other-500.csv successfully created!
2024-02-01 21:02:05,775 - librispeech_prepare - INFO - Creating csv lists in  results/transformer/74443/dev-clean.csv...
2024-02-01 21:02:11,654 - librispeech_prepare - INFO - results/transformer/74443/dev-clean.csv successfully created!
2024-02-01 21:02:11,705 - librispeech_prepare - INFO - Creating csv lists in  results/transformer/74443/test-clean.csv...
2024-02-01 21:02:17,525 - librispeech_prepare - INFO - results/transformer/74443/test-clean.csv successfully created!
2024-02-01 21:02:17,578 - librispeech_prepare - INFO - Creating csv lists in  results/transformer/74443/test-other.csv...
2024-02-01 21:02:23,402 - librispeech_prepare - INFO - results/transformer/74443/test-other.csv successfully created!
2024-02-01 21:02:23,683 - speechbrain.dataio.dataio - INFO - results/transformer/74443/train.csv is created.
2024-02-01 21:02:25,463 - speechbrain.utils.parameter_transfer - DEBUG - Collecting files (or symlinks) for pretraining in results/transformer/74443/save.
2024-02-01 21:02:25,464 - speechbrain.pretrained.fetching - INFO - Fetch lm.ckpt: Delegating to Huggingface hub, source speechbrain/asr-transformer-transformerlm-librispeech.
2024-02-01 21:02:25,709 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /speechbrain/asr-transformer-transformerlm-librispeech/resolve/main/lm.ckpt HTTP/1.1" 302 0
2024-02-01 21:02:25,711 - speechbrain.pretrained.fetching - INFO - HF fetch: /home/rajivratn/.cache/huggingface/hub/models--speechbrain--asr-transformer-transformerlm-librispeech/snapshots/4f5b13f894ba64cc36dc53e6c018a523e0a0a2f1/lm.ckpt
2024-02-01 21:02:25,712 - speechbrain.pretrained.fetching - INFO - Fetch tokenizer.ckpt: Delegating to Huggingface hub, source speechbrain/asr-transformer-transformerlm-librispeech.
2024-02-01 21:02:25,942 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /speechbrain/asr-transformer-transformerlm-librispeech/resolve/main/tokenizer.ckpt HTTP/1.1" 302 0
2024-02-01 21:02:25,943 - speechbrain.pretrained.fetching - INFO - HF fetch: /home/rajivratn/.cache/huggingface/hub/models--speechbrain--asr-transformer-transformerlm-librispeech/snapshots/4f5b13f894ba64cc36dc53e6c018a523e0a0a2f1/tokenizer.ckpt
2024-02-01 21:02:25,944 - speechbrain.utils.parameter_transfer - INFO - Loading pretrained files for: lm, tokenizer
2024-02-01 21:02:27,773 - speechbrain.core - INFO - Info: max_grad_norm arg from hparam file is used
2024-02-01 21:02:27,773 - speechbrain.core - INFO - Info: ckpt_interval_minutes arg from hparam file is used
2024-02-01 21:02:27,774 - speechbrain.core - INFO - Info: grad_accumulation_factor arg from hparam file is used
2024-02-01 21:02:28,297 - speechbrain.core - INFO - 221.4M trainable parameters in ASR
2024-02-01 21:02:28,300 - speechbrain.utils.checkpoints - INFO - Would load a checkpoint here, but none found yet.
2024-02-01 21:02:28,301 - speechbrain.utils.epoch_loop - INFO - Going into epoch 1
2024-02-01 21:02:31,224 - speechbrain.core - ERROR - Exception:
Traceback (most recent call last):
  File "/home/rajivratn/satyam/speechbrain/recipes/LibriSpeech/ASR/transformer/train_hubert.py", line 525, in <module>
    asr_brain.fit(
  File "/home/rajivratn/satyam/speechbrain/speechbrain/core.py", line 1366, in fit
    self._fit_train(train_set=train_set, epoch=epoch, enable=enable)
  File "/home/rajivratn/satyam/speechbrain/speechbrain/core.py", line 1193, in _fit_train
    loss = self.fit_batch(batch)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/rajivratn/satyam/speechbrain/recipes/LibriSpeech/ASR/transformer/train_hubert.py", line 278, in fit_batch
    outputs = self.compute_forward(batch, sb.Stage.TRAIN)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rajivratn/satyam/speechbrain/recipes/LibriSpeech/ASR/transformer/train_hubert.py", line 86, in compute_forward
    enc_out, src_key_padding_mask = self.modules.wav2vec2(wavs, wav_lens, src)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rajivratn/avinash/sb/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rajivratn/satyam/speechbrain/speechbrain/lobes/models/huggingface_wav2vec.py", line 333, in forward
    return self.extract_features(wav, wav_lens, src)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rajivratn/satyam/speechbrain/speechbrain/lobes/models/huggingface_wav2vec.py", line 360, in extract_features
    out = self.model(
          ^^^^^^^^^^^
  File "/home/rajivratn/avinash/sb/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rajivratn/avinash/sb/lib/python3.11/site-packages/transformers/models/hubert/modeling_hubert.py", line 1091, in forward
    encoder_outputs = self.encoder(
                      ^^^^^^^^^^^^^
  File "/home/rajivratn/avinash/sb/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rajivratn/avinash/sb/lib/python3.11/site-packages/transformers/models/hubert/modeling_hubert.py", line 738, in forward
    layer_outputs = layer(
                    ^^^^^^
  File "/home/rajivratn/avinash/sb/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rajivratn/avinash/sb/lib/python3.11/site-packages/transformers/models/hubert/modeling_hubert.py", line 589, in forward
    hidden_states, attn_weights, _ = self.attention(
                                     ^^^^^^^^^^^^^^^
  File "/home/rajivratn/avinash/sb/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rajivratn/avinash/sb/lib/python3.11/site-packages/transformers/models/hubert/modeling_hubert.py", line 488, in forward
    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1012.00 MiB (GPU 0; 39.41 GiB total capacity; 37.36 GiB already allocated; 164.06 MiB free; 37.73 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2024-02-01 21:04:19,395 - speechbrain.core - INFO - Beginning experiment!
2024-02-01 21:04:19,396 - speechbrain.core - INFO - Experiment folder: results/transformer/74443
2024-02-01 21:04:19,794 - speechbrain.utils.superpowers - DEBUG - Brotli @ file:///work/ci_py311/brotli-split_1676830125088/work
certifi @ file:///croot/certifi_1700501669400/work/certifi
cffi @ file:///croot/cffi_1700254295673/work
charset-normalizer @ file:///tmp/build/80754af9/charset-normalizer_1630003229654/work
cryptography @ file:///croot/cryptography_1702070282333/work
filelock @ file:///croot/filelock_1700591183607/work
fsspec==2023.12.2
gmpy2 @ file:///work/ci_py311/gmpy2_1676839849213/work
huggingface-hub==0.20.2
HyperPyYAML==1.2.2
idna @ file:///work/ci_py311/idna_1676822698822/work
Jinja2 @ file:///work/ci_py311/jinja2_1676823587943/work
joblib==1.3.2
MarkupSafe @ file:///croot/markupsafe_1704205993651/work
mkl-fft @ file:///croot/mkl_fft_1695058164594/work
mkl-random @ file:///croot/mkl_random_1695059800811/work
mkl-service==2.4.0
mpmath @ file:///croot/mpmath_1690848262763/work
networkx @ file:///croot/networkx_1690561992265/work
numpy @ file:///croot/numpy_and_numpy_base_1704311704800/work/dist/numpy-1.26.3-cp311-cp311-linux_x86_64.whl#sha256=10a078151ecec16bafb535f7487635217625fa06536dec8509e514648c78d626
packaging==23.2
Pillow @ file:///croot/pillow_1696580024257/work
pycparser @ file:///tmp/build/80754af9/pycparser_1636541352034/work
pyOpenSSL @ file:///croot/pyopenssl_1690223430423/work
PySocks @ file:///work/ci_py311/pysocks_1676822712504/work
PyYAML==6.0.1
regex==2023.12.25
requests @ file:///croot/requests_1690400202158/work
ruamel.yaml==0.18.5
ruamel.yaml.clib==0.2.8
safetensors==0.4.2
scipy==1.11.4
sentencepiece==0.1.99
# Editable install with no version control (speechbrain==0.5.16)
-e /home/rajivratn/satyam/speechbrain
sympy @ file:///croot/sympy_1701397643339/work
tokenizers==0.15.1
torch==2.0.1
torchaudio==2.0.2
torchvision==0.15.2
tqdm==4.66.1
transformers==4.37.1
triton==2.0.0
typing_extensions @ file:///croot/typing_extensions_1705005625920/work
urllib3 @ file:///croot/urllib3_1698257533958/work


2024-02-01 21:04:20,083 - librispeech_prepare - INFO - Skipping preparation, completed in previous run.
2024-02-01 21:04:21,873 - speechbrain.utils.parameter_transfer - DEBUG - Collecting files (or symlinks) for pretraining in results/transformer/74443/save.
2024-02-01 21:04:21,873 - speechbrain.pretrained.fetching - INFO - Fetch lm.ckpt: Using existing file/symlink in results/transformer/74443/save/lm.ckpt.
2024-02-01 21:04:21,874 - speechbrain.pretrained.fetching - INFO - Fetch tokenizer.ckpt: Using existing file/symlink in results/transformer/74443/save/tokenizer.ckpt.
2024-02-01 21:04:21,874 - speechbrain.utils.parameter_transfer - INFO - Loading pretrained files for: lm, tokenizer
2024-02-01 21:04:23,569 - speechbrain.core - INFO - Info: max_grad_norm arg from hparam file is used
2024-02-01 21:04:23,570 - speechbrain.core - INFO - Info: ckpt_interval_minutes arg from hparam file is used
2024-02-01 21:04:23,570 - speechbrain.core - INFO - Info: grad_accumulation_factor arg from hparam file is used
2024-02-01 21:04:24,186 - speechbrain.core - INFO - 221.4M trainable parameters in ASR
2024-02-01 21:04:24,188 - speechbrain.utils.checkpoints - INFO - Would load a checkpoint here, but none found yet.
2024-02-01 21:04:24,188 - speechbrain.utils.epoch_loop - INFO - Going into epoch 1
2024-02-01 21:04:26,906 - speechbrain.core - ERROR - Exception:
Traceback (most recent call last):
  File "/home/rajivratn/satyam/speechbrain/recipes/LibriSpeech/ASR/transformer/train_hubert.py", line 525, in <module>
    asr_brain.fit(
  File "/home/rajivratn/satyam/speechbrain/speechbrain/core.py", line 1366, in fit
    self._fit_train(train_set=train_set, epoch=epoch, enable=enable)
  File "/home/rajivratn/satyam/speechbrain/speechbrain/core.py", line 1193, in _fit_train
    loss = self.fit_batch(batch)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/rajivratn/satyam/speechbrain/recipes/LibriSpeech/ASR/transformer/train_hubert.py", line 278, in fit_batch
    outputs = self.compute_forward(batch, sb.Stage.TRAIN)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rajivratn/satyam/speechbrain/recipes/LibriSpeech/ASR/transformer/train_hubert.py", line 86, in compute_forward
    enc_out, src_key_padding_mask = self.modules.wav2vec2(wavs, wav_lens, src)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rajivratn/avinash/sb/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rajivratn/satyam/speechbrain/speechbrain/lobes/models/huggingface_wav2vec.py", line 333, in forward
    return self.extract_features(wav, wav_lens, src)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rajivratn/satyam/speechbrain/speechbrain/lobes/models/huggingface_wav2vec.py", line 360, in extract_features
    out = self.model(
          ^^^^^^^^^^^
  File "/home/rajivratn/avinash/sb/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rajivratn/avinash/sb/lib/python3.11/site-packages/transformers/models/hubert/modeling_hubert.py", line 1091, in forward
    encoder_outputs = self.encoder(
                      ^^^^^^^^^^^^^
  File "/home/rajivratn/avinash/sb/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rajivratn/avinash/sb/lib/python3.11/site-packages/transformers/models/hubert/modeling_hubert.py", line 738, in forward
    layer_outputs = layer(
                    ^^^^^^
  File "/home/rajivratn/avinash/sb/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rajivratn/avinash/sb/lib/python3.11/site-packages/transformers/models/hubert/modeling_hubert.py", line 589, in forward
    hidden_states, attn_weights, _ = self.attention(
                                     ^^^^^^^^^^^^^^^
  File "/home/rajivratn/avinash/sb/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rajivratn/avinash/sb/lib/python3.11/site-packages/transformers/models/hubert/modeling_hubert.py", line 488, in forward
    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1012.00 MiB (GPU 0; 39.41 GiB total capacity; 37.36 GiB already allocated; 164.06 MiB free; 37.73 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2024-02-01 21:06:05,751 - speechbrain.core - INFO - Beginning experiment!
2024-02-01 21:06:05,752 - speechbrain.core - INFO - Experiment folder: results/transformer/74443
2024-02-01 21:06:06,149 - speechbrain.utils.superpowers - DEBUG - Brotli @ file:///work/ci_py311/brotli-split_1676830125088/work
certifi @ file:///croot/certifi_1700501669400/work/certifi
cffi @ file:///croot/cffi_1700254295673/work
charset-normalizer @ file:///tmp/build/80754af9/charset-normalizer_1630003229654/work
cryptography @ file:///croot/cryptography_1702070282333/work
filelock @ file:///croot/filelock_1700591183607/work
fsspec==2023.12.2
gmpy2 @ file:///work/ci_py311/gmpy2_1676839849213/work
huggingface-hub==0.20.2
HyperPyYAML==1.2.2
idna @ file:///work/ci_py311/idna_1676822698822/work
Jinja2 @ file:///work/ci_py311/jinja2_1676823587943/work
joblib==1.3.2
MarkupSafe @ file:///croot/markupsafe_1704205993651/work
mkl-fft @ file:///croot/mkl_fft_1695058164594/work
mkl-random @ file:///croot/mkl_random_1695059800811/work
mkl-service==2.4.0
mpmath @ file:///croot/mpmath_1690848262763/work
networkx @ file:///croot/networkx_1690561992265/work
numpy @ file:///croot/numpy_and_numpy_base_1704311704800/work/dist/numpy-1.26.3-cp311-cp311-linux_x86_64.whl#sha256=10a078151ecec16bafb535f7487635217625fa06536dec8509e514648c78d626
packaging==23.2
Pillow @ file:///croot/pillow_1696580024257/work
pycparser @ file:///tmp/build/80754af9/pycparser_1636541352034/work
pyOpenSSL @ file:///croot/pyopenssl_1690223430423/work
PySocks @ file:///work/ci_py311/pysocks_1676822712504/work
PyYAML==6.0.1
regex==2023.12.25
requests @ file:///croot/requests_1690400202158/work
ruamel.yaml==0.18.5
ruamel.yaml.clib==0.2.8
safetensors==0.4.2
scipy==1.11.4
sentencepiece==0.1.99
# Editable install with no version control (speechbrain==0.5.16)
-e /home/rajivratn/satyam/speechbrain
sympy @ file:///croot/sympy_1701397643339/work
tokenizers==0.15.1
torch==2.0.1
torchaudio==2.0.2
torchvision==0.15.2
tqdm==4.66.1
transformers==4.37.1
triton==2.0.0
typing_extensions @ file:///croot/typing_extensions_1705005625920/work
urllib3 @ file:///croot/urllib3_1698257533958/work


2024-02-01 21:06:07,611 - librispeech_prepare - INFO - Skipping preparation, completed in previous run.
2024-02-01 21:06:09,338 - speechbrain.utils.parameter_transfer - DEBUG - Collecting files (or symlinks) for pretraining in results/transformer/74443/save.
2024-02-01 21:06:09,339 - speechbrain.pretrained.fetching - INFO - Fetch lm.ckpt: Using existing file/symlink in results/transformer/74443/save/lm.ckpt.
2024-02-01 21:06:09,339 - speechbrain.pretrained.fetching - INFO - Fetch tokenizer.ckpt: Using existing file/symlink in results/transformer/74443/save/tokenizer.ckpt.
2024-02-01 21:06:09,340 - speechbrain.utils.parameter_transfer - INFO - Loading pretrained files for: lm, tokenizer
2024-02-01 21:06:09,660 - speechbrain.core - INFO - Info: max_grad_norm arg from hparam file is used
2024-02-01 21:06:09,660 - speechbrain.core - INFO - Info: ckpt_interval_minutes arg from hparam file is used
2024-02-01 21:06:09,660 - speechbrain.core - INFO - Info: grad_accumulation_factor arg from hparam file is used
2024-02-01 21:06:10,135 - speechbrain.core - INFO - 221.4M trainable parameters in ASR
2024-02-01 21:06:10,170 - speechbrain.utils.checkpoints - INFO - Would load a checkpoint here, but none found yet.
2024-02-01 21:06:10,170 - speechbrain.utils.epoch_loop - INFO - Going into epoch 1
2024-02-01 21:06:12,968 - speechbrain.core - ERROR - Exception:
Traceback (most recent call last):
  File "/home/rajivratn/satyam/speechbrain/recipes/LibriSpeech/ASR/transformer/train_hubert.py", line 525, in <module>
    asr_brain.fit(
  File "/home/rajivratn/satyam/speechbrain/speechbrain/core.py", line 1366, in fit
    self._fit_train(train_set=train_set, epoch=epoch, enable=enable)
  File "/home/rajivratn/satyam/speechbrain/speechbrain/core.py", line 1193, in _fit_train
    loss = self.fit_batch(batch)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/rajivratn/satyam/speechbrain/recipes/LibriSpeech/ASR/transformer/train_hubert.py", line 278, in fit_batch
    outputs = self.compute_forward(batch, sb.Stage.TRAIN)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rajivratn/satyam/speechbrain/recipes/LibriSpeech/ASR/transformer/train_hubert.py", line 86, in compute_forward
    enc_out, src_key_padding_mask = self.modules.wav2vec2(wavs, wav_lens, src)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rajivratn/avinash/sb/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rajivratn/avinash/sb/lib/python3.11/site-packages/torch/nn/parallel/distributed.py", line 1156, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rajivratn/avinash/sb/lib/python3.11/site-packages/torch/nn/parallel/distributed.py", line 1110, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])  # type: ignore[index]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rajivratn/avinash/sb/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rajivratn/satyam/speechbrain/speechbrain/lobes/models/huggingface_wav2vec.py", line 333, in forward
    return self.extract_features(wav, wav_lens, src)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rajivratn/satyam/speechbrain/speechbrain/lobes/models/huggingface_wav2vec.py", line 360, in extract_features
    out = self.model(
          ^^^^^^^^^^^
  File "/home/rajivratn/avinash/sb/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rajivratn/avinash/sb/lib/python3.11/site-packages/transformers/models/hubert/modeling_hubert.py", line 1091, in forward
    encoder_outputs = self.encoder(
                      ^^^^^^^^^^^^^
  File "/home/rajivratn/avinash/sb/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rajivratn/avinash/sb/lib/python3.11/site-packages/transformers/models/hubert/modeling_hubert.py", line 738, in forward
    layer_outputs = layer(
                    ^^^^^^
  File "/home/rajivratn/avinash/sb/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rajivratn/avinash/sb/lib/python3.11/site-packages/transformers/models/hubert/modeling_hubert.py", line 596, in forward
    hidden_states = hidden_states + self.feed_forward(hidden_states)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rajivratn/avinash/sb/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rajivratn/avinash/sb/lib/python3.11/site-packages/transformers/models/hubert/modeling_hubert.py", line 565, in forward
    hidden_states = self.intermediate_dropout(hidden_states)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rajivratn/avinash/sb/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rajivratn/avinash/sb/lib/python3.11/site-packages/torch/nn/modules/dropout.py", line 59, in forward
    return F.dropout(input, self.p, self.training, self.inplace)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rajivratn/avinash/sb/lib/python3.11/site-packages/torch/nn/functional.py", line 1252, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 308.00 MiB (GPU 0; 39.41 GiB total capacity; 37.21 GiB already allocated; 206.06 MiB free; 37.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2024-02-01 21:07:07,511 - speechbrain.core - INFO - Beginning experiment!
2024-02-01 21:07:07,511 - speechbrain.core - INFO - Experiment folder: results/transformer/74443
2024-02-01 21:07:07,906 - speechbrain.utils.superpowers - DEBUG - Brotli @ file:///work/ci_py311/brotli-split_1676830125088/work
certifi @ file:///croot/certifi_1700501669400/work/certifi
cffi @ file:///croot/cffi_1700254295673/work
charset-normalizer @ file:///tmp/build/80754af9/charset-normalizer_1630003229654/work
cryptography @ file:///croot/cryptography_1702070282333/work
filelock @ file:///croot/filelock_1700591183607/work
fsspec==2023.12.2
gmpy2 @ file:///work/ci_py311/gmpy2_1676839849213/work
huggingface-hub==0.20.2
HyperPyYAML==1.2.2
idna @ file:///work/ci_py311/idna_1676822698822/work
Jinja2 @ file:///work/ci_py311/jinja2_1676823587943/work
joblib==1.3.2
MarkupSafe @ file:///croot/markupsafe_1704205993651/work
mkl-fft @ file:///croot/mkl_fft_1695058164594/work
mkl-random @ file:///croot/mkl_random_1695059800811/work
mkl-service==2.4.0
mpmath @ file:///croot/mpmath_1690848262763/work
networkx @ file:///croot/networkx_1690561992265/work
numpy @ file:///croot/numpy_and_numpy_base_1704311704800/work/dist/numpy-1.26.3-cp311-cp311-linux_x86_64.whl#sha256=10a078151ecec16bafb535f7487635217625fa06536dec8509e514648c78d626
packaging==23.2
Pillow @ file:///croot/pillow_1696580024257/work
pycparser @ file:///tmp/build/80754af9/pycparser_1636541352034/work
pyOpenSSL @ file:///croot/pyopenssl_1690223430423/work
PySocks @ file:///work/ci_py311/pysocks_1676822712504/work
PyYAML==6.0.1
regex==2023.12.25
requests @ file:///croot/requests_1690400202158/work
ruamel.yaml==0.18.5
ruamel.yaml.clib==0.2.8
safetensors==0.4.2
scipy==1.11.4
sentencepiece==0.1.99
# Editable install with no version control (speechbrain==0.5.16)
-e /home/rajivratn/satyam/speechbrain
sympy @ file:///croot/sympy_1701397643339/work
tokenizers==0.15.1
torch==2.0.1
torchaudio==2.0.2
torchvision==0.15.2
tqdm==4.66.1
transformers==4.37.1
triton==2.0.0
typing_extensions @ file:///croot/typing_extensions_1705005625920/work
urllib3 @ file:///croot/urllib3_1698257533958/work


2024-02-01 21:07:09,366 - librispeech_prepare - INFO - Skipping preparation, completed in previous run.
2024-02-01 21:07:11,106 - speechbrain.utils.parameter_transfer - DEBUG - Collecting files (or symlinks) for pretraining in results/transformer/74443/save.
2024-02-01 21:07:11,107 - speechbrain.pretrained.fetching - INFO - Fetch lm.ckpt: Using existing file/symlink in results/transformer/74443/save/lm.ckpt.
2024-02-01 21:07:11,107 - speechbrain.pretrained.fetching - INFO - Fetch tokenizer.ckpt: Using existing file/symlink in results/transformer/74443/save/tokenizer.ckpt.
2024-02-01 21:07:11,108 - speechbrain.utils.parameter_transfer - INFO - Loading pretrained files for: lm, tokenizer
2024-02-01 21:07:11,414 - speechbrain.core - INFO - Info: max_grad_norm arg from hparam file is used
2024-02-01 21:07:11,414 - speechbrain.core - INFO - Info: ckpt_interval_minutes arg from hparam file is used
2024-02-01 21:07:11,414 - speechbrain.core - INFO - Info: grad_accumulation_factor arg from hparam file is used
2024-02-01 21:07:11,638 - speechbrain.core - INFO - 221.4M trainable parameters in ASR
2024-02-01 21:07:11,671 - speechbrain.utils.checkpoints - INFO - Would load a checkpoint here, but none found yet.
2024-02-01 21:07:11,672 - speechbrain.utils.epoch_loop - INFO - Going into epoch 1
2024-02-01 21:07:14,441 - speechbrain.core - ERROR - Exception:
Traceback (most recent call last):
  File "/home/rajivratn/satyam/speechbrain/recipes/LibriSpeech/ASR/transformer/train_hubert.py", line 525, in <module>
    asr_brain.fit(
  File "/home/rajivratn/satyam/speechbrain/speechbrain/core.py", line 1366, in fit
    self._fit_train(train_set=train_set, epoch=epoch, enable=enable)
  File "/home/rajivratn/satyam/speechbrain/speechbrain/core.py", line 1193, in _fit_train
    loss = self.fit_batch(batch)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/rajivratn/satyam/speechbrain/recipes/LibriSpeech/ASR/transformer/train_hubert.py", line 278, in fit_batch
    outputs = self.compute_forward(batch, sb.Stage.TRAIN)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rajivratn/satyam/speechbrain/recipes/LibriSpeech/ASR/transformer/train_hubert.py", line 86, in compute_forward
    enc_out, src_key_padding_mask = self.modules.wav2vec2(wavs, wav_lens, src)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rajivratn/avinash/sb/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rajivratn/avinash/sb/lib/python3.11/site-packages/torch/nn/parallel/distributed.py", line 1156, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rajivratn/avinash/sb/lib/python3.11/site-packages/torch/nn/parallel/distributed.py", line 1110, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])  # type: ignore[index]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rajivratn/avinash/sb/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rajivratn/satyam/speechbrain/speechbrain/lobes/models/huggingface_wav2vec.py", line 333, in forward
    return self.extract_features(wav, wav_lens, src)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rajivratn/satyam/speechbrain/speechbrain/lobes/models/huggingface_wav2vec.py", line 360, in extract_features
    out = self.model(
          ^^^^^^^^^^^
  File "/home/rajivratn/avinash/sb/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rajivratn/avinash/sb/lib/python3.11/site-packages/transformers/models/hubert/modeling_hubert.py", line 1091, in forward
    encoder_outputs = self.encoder(
                      ^^^^^^^^^^^^^
  File "/home/rajivratn/avinash/sb/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rajivratn/avinash/sb/lib/python3.11/site-packages/transformers/models/hubert/modeling_hubert.py", line 738, in forward
    layer_outputs = layer(
                    ^^^^^^
  File "/home/rajivratn/avinash/sb/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rajivratn/avinash/sb/lib/python3.11/site-packages/transformers/models/hubert/modeling_hubert.py", line 596, in forward
    hidden_states = hidden_states + self.feed_forward(hidden_states)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rajivratn/avinash/sb/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rajivratn/avinash/sb/lib/python3.11/site-packages/transformers/models/hubert/modeling_hubert.py", line 565, in forward
    hidden_states = self.intermediate_dropout(hidden_states)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rajivratn/avinash/sb/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rajivratn/avinash/sb/lib/python3.11/site-packages/torch/nn/modules/dropout.py", line 59, in forward
    return F.dropout(input, self.p, self.training, self.inplace)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rajivratn/avinash/sb/lib/python3.11/site-packages/torch/nn/functional.py", line 1252, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 308.00 MiB (GPU 0; 39.41 GiB total capacity; 37.21 GiB already allocated; 206.06 MiB free; 37.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2024-02-02 00:27:16,180 - speechbrain.core - INFO - Beginning experiment!
2024-02-02 00:27:16,180 - speechbrain.core - INFO - Experiment folder: results/transformer/74443
2024-02-02 00:27:16,577 - speechbrain.utils.superpowers - DEBUG - Brotli @ file:///work/ci_py311/brotli-split_1676830125088/work
certifi @ file:///croot/certifi_1700501669400/work/certifi
cffi @ file:///croot/cffi_1700254295673/work
charset-normalizer @ file:///tmp/build/80754af9/charset-normalizer_1630003229654/work
cryptography @ file:///croot/cryptography_1702070282333/work
filelock @ file:///croot/filelock_1700591183607/work
fsspec==2023.12.2
gmpy2 @ file:///work/ci_py311/gmpy2_1676839849213/work
huggingface-hub==0.20.2
HyperPyYAML==1.2.2
idna @ file:///work/ci_py311/idna_1676822698822/work
Jinja2 @ file:///work/ci_py311/jinja2_1676823587943/work
joblib==1.3.2
MarkupSafe @ file:///croot/markupsafe_1704205993651/work
mkl-fft @ file:///croot/mkl_fft_1695058164594/work
mkl-random @ file:///croot/mkl_random_1695059800811/work
mkl-service==2.4.0
mpmath @ file:///croot/mpmath_1690848262763/work
networkx @ file:///croot/networkx_1690561992265/work
numpy @ file:///croot/numpy_and_numpy_base_1704311704800/work/dist/numpy-1.26.3-cp311-cp311-linux_x86_64.whl#sha256=10a078151ecec16bafb535f7487635217625fa06536dec8509e514648c78d626
packaging==23.2
Pillow @ file:///croot/pillow_1696580024257/work
pycparser @ file:///tmp/build/80754af9/pycparser_1636541352034/work
pyOpenSSL @ file:///croot/pyopenssl_1690223430423/work
PySocks @ file:///work/ci_py311/pysocks_1676822712504/work
PyYAML==6.0.1
regex==2023.12.25
requests @ file:///croot/requests_1690400202158/work
ruamel.yaml==0.18.5
ruamel.yaml.clib==0.2.8
safetensors==0.4.2
scipy==1.11.4
sentencepiece==0.1.99
# Editable install with no version control (speechbrain==0.5.16)
-e /home/rajivratn/satyam/speechbrain
sympy @ file:///croot/sympy_1701397643339/work
tokenizers==0.15.1
torch==2.0.1
torchaudio==2.0.2
torchvision==0.15.2
tqdm==4.66.1
transformers==4.37.1
triton==2.0.0
typing_extensions @ file:///croot/typing_extensions_1705005625920/work
urllib3 @ file:///croot/urllib3_1698257533958/work


2024-02-02 00:27:18,131 - librispeech_prepare - INFO - Skipping preparation, completed in previous run.
2024-02-02 00:27:19,906 - speechbrain.utils.parameter_transfer - DEBUG - Collecting files (or symlinks) for pretraining in results/transformer/74443/save.
2024-02-02 00:27:19,906 - speechbrain.pretrained.fetching - INFO - Fetch lm.ckpt: Using existing file/symlink in results/transformer/74443/save/lm.ckpt.
2024-02-02 00:27:19,907 - speechbrain.pretrained.fetching - INFO - Fetch tokenizer.ckpt: Using existing file/symlink in results/transformer/74443/save/tokenizer.ckpt.
2024-02-02 00:27:19,907 - speechbrain.utils.parameter_transfer - INFO - Loading pretrained files for: lm, tokenizer
2024-02-02 00:27:20,213 - speechbrain.core - INFO - Info: max_grad_norm arg from hparam file is used
2024-02-02 00:27:20,214 - speechbrain.core - INFO - Info: ckpt_interval_minutes arg from hparam file is used
2024-02-02 00:27:20,214 - speechbrain.core - INFO - Info: grad_accumulation_factor arg from hparam file is used
2024-02-02 00:27:20,729 - speechbrain.core - INFO - 127.1M trainable parameters in ASR
2024-02-02 00:27:20,757 - speechbrain.utils.checkpoints - INFO - Would load a checkpoint here, but none found yet.
2024-02-02 00:27:20,757 - speechbrain.utils.epoch_loop - INFO - Going into epoch 1
2024-02-02 00:27:24,403 - speechbrain.core - ERROR - Exception:
Traceback (most recent call last):
  File "/home/rajivratn/satyam/speechbrain/recipes/LibriSpeech/ASR/transformer/train_hubert.py", line 525, in <module>
    asr_brain.fit(
  File "/home/rajivratn/satyam/speechbrain/speechbrain/core.py", line 1366, in fit
    self._fit_train(train_set=train_set, epoch=epoch, enable=enable)
  File "/home/rajivratn/satyam/speechbrain/speechbrain/core.py", line 1193, in _fit_train
    loss = self.fit_batch(batch)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/rajivratn/satyam/speechbrain/recipes/LibriSpeech/ASR/transformer/train_hubert.py", line 278, in fit_batch
    outputs = self.compute_forward(batch, sb.Stage.TRAIN)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rajivratn/satyam/speechbrain/recipes/LibriSpeech/ASR/transformer/train_hubert.py", line 88, in compute_forward
    pred = self.modules.Transformer(enc_out, src_key_padding_mask, tokens_bos, pad_idx=self.hparams.pad_index)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rajivratn/avinash/sb/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rajivratn/avinash/sb/lib/python3.11/site-packages/torch/nn/parallel/distributed.py", line 1139, in forward
    if torch.is_grad_enabled() and self.reducer._rebuild_buckets():
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected to have finished reduction in the prior iteration before starting a new one. This error indicates that your module has parameters that were not used in producing loss. You can enable unused parameter detection by passing the keyword argument `find_unused_parameters=True` to `torch.nn.parallel.DistributedDataParallel`, and by 
making sure all `forward` function outputs participate in calculating loss. 
If you already have done the above, then the distributed data parallel module wasn't able to locate the output tensors in the return value of your module's `forward` function. Please include the loss function and the structure of the return value of `forward` of your module when reporting this issue (e.g. list, dict, iterable).
Parameter indices which did not receive grad for rank 0: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 ...
 In addition, you can set the environment variable TORCH_DISTRIBUTED_DEBUG to either INFO or DETAIL to print out information about which particular parameters did not receive gradient on this rank as part of this error
2024-02-02 00:28:01,859 - speechbrain.core - INFO - Beginning experiment!
2024-02-02 00:28:01,859 - speechbrain.core - INFO - Experiment folder: results/transformer/74443
2024-02-02 00:28:02,254 - speechbrain.utils.superpowers - DEBUG - Brotli @ file:///work/ci_py311/brotli-split_1676830125088/work
certifi @ file:///croot/certifi_1700501669400/work/certifi
cffi @ file:///croot/cffi_1700254295673/work
charset-normalizer @ file:///tmp/build/80754af9/charset-normalizer_1630003229654/work
cryptography @ file:///croot/cryptography_1702070282333/work
filelock @ file:///croot/filelock_1700591183607/work
fsspec==2023.12.2
gmpy2 @ file:///work/ci_py311/gmpy2_1676839849213/work
huggingface-hub==0.20.2
HyperPyYAML==1.2.2
idna @ file:///work/ci_py311/idna_1676822698822/work
Jinja2 @ file:///work/ci_py311/jinja2_1676823587943/work
joblib==1.3.2
MarkupSafe @ file:///croot/markupsafe_1704205993651/work
mkl-fft @ file:///croot/mkl_fft_1695058164594/work
mkl-random @ file:///croot/mkl_random_1695059800811/work
mkl-service==2.4.0
mpmath @ file:///croot/mpmath_1690848262763/work
networkx @ file:///croot/networkx_1690561992265/work
numpy @ file:///croot/numpy_and_numpy_base_1704311704800/work/dist/numpy-1.26.3-cp311-cp311-linux_x86_64.whl#sha256=10a078151ecec16bafb535f7487635217625fa06536dec8509e514648c78d626
packaging==23.2
Pillow @ file:///croot/pillow_1696580024257/work
pycparser @ file:///tmp/build/80754af9/pycparser_1636541352034/work
pyOpenSSL @ file:///croot/pyopenssl_1690223430423/work
PySocks @ file:///work/ci_py311/pysocks_1676822712504/work
PyYAML==6.0.1
regex==2023.12.25
requests @ file:///croot/requests_1690400202158/work
ruamel.yaml==0.18.5
ruamel.yaml.clib==0.2.8
safetensors==0.4.2
scipy==1.11.4
sentencepiece==0.1.99
# Editable install with no version control (speechbrain==0.5.16)
-e /home/rajivratn/satyam/speechbrain
sympy @ file:///croot/sympy_1701397643339/work
tokenizers==0.15.1
torch==2.0.1
torchaudio==2.0.2
torchvision==0.15.2
tqdm==4.66.1
transformers==4.37.1
triton==2.0.0
typing_extensions @ file:///croot/typing_extensions_1705005625920/work
urllib3 @ file:///croot/urllib3_1698257533958/work


2024-02-02 00:28:02,436 - librispeech_prepare - INFO - Skipping preparation, completed in previous run.
2024-02-02 00:28:04,190 - speechbrain.utils.parameter_transfer - DEBUG - Collecting files (or symlinks) for pretraining in results/transformer/74443/save.
2024-02-02 00:28:04,190 - speechbrain.pretrained.fetching - INFO - Fetch lm.ckpt: Using existing file/symlink in results/transformer/74443/save/lm.ckpt.
2024-02-02 00:28:04,190 - speechbrain.pretrained.fetching - INFO - Fetch tokenizer.ckpt: Using existing file/symlink in results/transformer/74443/save/tokenizer.ckpt.
2024-02-02 00:28:04,191 - speechbrain.utils.parameter_transfer - INFO - Loading pretrained files for: lm, tokenizer
2024-02-02 00:28:05,790 - speechbrain.core - INFO - Info: max_grad_norm arg from hparam file is used
2024-02-02 00:28:05,790 - speechbrain.core - INFO - Info: ckpt_interval_minutes arg from hparam file is used
2024-02-02 00:28:05,790 - speechbrain.core - INFO - Info: grad_accumulation_factor arg from hparam file is used
2024-02-02 00:28:06,358 - speechbrain.core - INFO - 127.1M trainable parameters in ASR
2024-02-02 00:28:06,361 - speechbrain.utils.checkpoints - INFO - Would load a checkpoint here, but none found yet.
2024-02-02 00:28:06,361 - speechbrain.utils.epoch_loop - INFO - Going into epoch 1
2024-02-02 00:58:07,714 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-02+00-58-06+00
2024-02-02 01:28:09,521 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-02+01-28-08+00
2024-02-02 01:28:09,622 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-02+00-58-06+00
2024-02-02 01:58:11,197 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-02+01-58-09+00
2024-02-02 01:58:11,310 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-02+01-28-08+00
2024-02-02 02:01:37,167 - speechbrain.utils.train_logger - INFO - epoch: 1, lr: 8.78e-05, steps: 2197, optimizer: Adam - train loss: 7.60e+02 - valid loss: 1.34e+02, valid ACC: 3.29e-01
2024-02-02 02:01:38,422 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-02+02-01-37+00
2024-02-02 02:01:38,432 - speechbrain.utils.epoch_loop - INFO - Going into epoch 2
2024-02-02 02:31:39,935 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-02+02-31-38+00
2024-02-02 02:31:40,071 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-02+01-58-09+00
2024-02-02 03:01:41,322 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-02+03-01-40+00
2024-02-02 03:01:41,485 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-02+02-31-38+00
2024-02-02 03:31:42,845 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-02+03-31-41+00
2024-02-02 03:31:42,997 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-02+03-01-40+00
2024-02-02 03:34:44,431 - speechbrain.utils.train_logger - INFO - epoch: 2, lr: 1.76e-04, steps: 4394, optimizer: Adam - train loss: 2.15e+02 - valid loss: 58.04, valid ACC: 7.34e-01
2024-02-02 03:34:45,730 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-02+03-34-44+00
2024-02-02 03:34:45,753 - speechbrain.utils.epoch_loop - INFO - Going into epoch 3
2024-02-02 04:04:47,128 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-02+04-04-45+00
2024-02-02 04:04:47,294 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-02+03-31-41+00
2024-02-02 04:34:48,717 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-02+04-34-47+00
2024-02-02 04:34:48,878 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-02+04-04-45+00
2024-02-02 05:04:50,025 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-02+05-04-48+00
2024-02-02 05:04:50,172 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-02+04-34-47+00
2024-02-02 05:07:50,852 - speechbrain.utils.train_logger - INFO - epoch: 3, lr: 2.64e-04, steps: 6591, optimizer: Adam - train loss: 1.77e+02 - valid loss: 32.74, valid ACC: 8.66e-01
2024-02-02 05:07:51,955 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-02+05-07-50+00
2024-02-02 05:07:51,999 - speechbrain.utils.epoch_loop - INFO - Going into epoch 4
2024-02-02 05:37:53,714 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-02+05-37-52+00
2024-02-02 05:37:53,902 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-02+05-04-48+00
2024-02-02 06:07:55,253 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-02+06-07-53+00
2024-02-02 06:07:55,439 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-02+05-37-52+00
2024-02-02 06:37:57,355 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-02+06-37-55+00
2024-02-02 06:37:57,553 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-02+06-07-53+00
2024-02-02 06:40:50,386 - speechbrain.utils.train_logger - INFO - epoch: 4, lr: 3.51e-04, steps: 8788, optimizer: Adam - train loss: 1.66e+02 - valid loss: 26.91, valid ACC: 8.84e-01
2024-02-02 06:40:51,669 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-02+06-40-50+00
2024-02-02 06:40:51,740 - speechbrain.utils.epoch_loop - INFO - Going into epoch 5
2024-02-02 07:10:53,218 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-02+07-10-51+00
2024-02-02 07:10:53,428 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-02+06-37-55+00
2024-02-02 07:40:55,109 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-02+07-40-53+00
2024-02-02 07:40:55,278 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-02+07-10-51+00
2024-02-02 08:10:57,010 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-02+08-10-55+00
2024-02-02 08:10:57,105 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-02+07-40-53+00
2024-02-02 08:18:04,209 - speechbrain.utils.train_logger - INFO - epoch: 5, lr: 4.39e-04, steps: 10985, optimizer: Adam - train loss: 1.61e+02 - valid loss: 22.66, valid ACC: 9.03e-01
2024-02-02 08:18:05,304 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-02+08-18-04+00
2024-02-02 08:18:05,409 - speechbrain.utils.epoch_loop - INFO - Going into epoch 6
2024-02-02 08:48:07,736 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-02+08-48-06+00
2024-02-02 08:48:07,862 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-02+08-10-55+00
2024-02-02 09:18:09,314 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-02+09-18-08+00
2024-02-02 09:18:09,445 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-02+08-48-06+00
2024-02-02 09:48:10,715 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-02+09-48-09+00
2024-02-02 09:48:10,856 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-02+09-18-08+00
2024-02-02 09:51:05,202 - speechbrain.utils.train_logger - INFO - epoch: 6, lr: 5.27e-04, steps: 13182, optimizer: Adam - train loss: 1.58e+02 - valid loss: 20.89, valid ACC: 9.06e-01
2024-02-02 09:51:06,342 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-02+09-51-05+00
2024-02-02 09:51:06,490 - speechbrain.utils.epoch_loop - INFO - Going into epoch 7
2024-02-02 10:21:08,264 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-02+10-21-07+00
2024-02-02 10:21:08,510 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-02+09-48-09+00
2024-02-02 10:51:09,753 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-02+10-51-08+00
2024-02-02 10:51:10,001 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-02+10-21-07+00
2024-02-02 11:21:11,373 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-02+11-21-10+00
2024-02-02 11:21:11,674 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-02+10-51-08+00
2024-02-02 11:24:07,706 - speechbrain.utils.train_logger - INFO - epoch: 7, lr: 6.15e-04, steps: 15379, optimizer: Adam - train loss: 1.56e+02 - valid loss: 19.92, valid ACC: 9.07e-01
2024-02-02 11:24:08,911 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-02+11-24-07+00
2024-02-02 11:24:09,100 - speechbrain.utils.epoch_loop - INFO - Going into epoch 8
2024-02-02 11:54:10,442 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-02+11-54-09+00
2024-02-02 11:54:10,760 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-02+11-21-10+00
2024-02-02 12:24:12,310 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-02+12-24-11+00
2024-02-02 12:24:12,671 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-02+11-54-09+00
2024-02-02 12:54:13,913 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-02+12-54-12+00
2024-02-02 12:54:14,294 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-02+12-24-11+00
2024-02-02 12:57:13,981 - speechbrain.utils.train_logger - INFO - epoch: 8, lr: 7.03e-04, steps: 17576, optimizer: Adam - train loss: 1.54e+02 - valid loss: 18.86, valid ACC: 9.14e-01
2024-02-02 12:57:15,299 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-02+12-57-13+00
2024-02-02 12:57:15,541 - speechbrain.utils.epoch_loop - INFO - Going into epoch 9
2024-02-02 13:27:17,104 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-02+13-27-15+00
2024-02-02 13:27:17,526 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-02+12-54-12+00
2024-02-02 13:57:19,335 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-02+13-57-18+00
2024-02-02 13:57:19,627 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-02+13-27-15+00
2024-02-02 14:27:21,430 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-02+14-27-20+00
2024-02-02 14:27:21,856 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-02+13-57-18+00
2024-02-02 14:30:26,130 - speechbrain.utils.train_logger - INFO - epoch: 9, lr: 7.91e-04, steps: 19773, optimizer: Adam - train loss: 1.52e+02 - valid loss: 18.08, valid ACC: 9.17e-01
2024-02-02 14:30:27,441 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-02+14-30-26+00
2024-02-02 14:30:27,742 - speechbrain.utils.epoch_loop - INFO - Going into epoch 10
2024-02-02 15:00:29,182 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-02+15-00-27+00
2024-02-02 15:00:29,617 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-02+14-27-20+00
2024-02-02 15:30:31,401 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-02+15-30-30+00
2024-02-02 15:30:31,890 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-02+15-00-27+00
2024-02-02 16:00:33,400 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-02+16-00-32+00
2024-02-02 16:00:33,900 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-02+15-30-30+00
2024-02-02 17:58:20,639 - speechbrain.utils.train_logger - INFO - epoch: 10, lr: 8.79e-04, steps: 21970, optimizer: Adam - train loss: 1.50e+02 - valid loss: 17.66, valid ACC: 9.19e-01, valid WER: 9.01
2024-02-02 17:58:21,940 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-02+17-58-20+00
2024-02-02 17:58:22,309 - speechbrain.utils.epoch_loop - INFO - Going into epoch 11
2024-02-02 18:28:24,007 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-02+18-28-22+00
2024-02-02 18:28:24,430 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-02+16-00-32+00
2024-02-02 18:58:25,687 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-02+18-58-24+00
2024-02-02 18:58:26,205 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-02+18-28-22+00
2024-02-02 19:28:27,387 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-02+19-28-26+00
2024-02-02 19:28:27,911 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-02+18-58-24+00
2024-02-02 19:31:30,598 - speechbrain.utils.train_logger - INFO - epoch: 11, lr: 9.67e-04, steps: 24167, optimizer: Adam - train loss: 1.49e+02 - valid loss: 18.21, valid ACC: 9.18e-01
2024-02-02 19:31:31,716 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-02+19-31-30+00
2024-02-02 19:31:32,161 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-02+02-01-37+00
2024-02-02 19:31:32,161 - speechbrain.utils.epoch_loop - INFO - Going into epoch 12
2024-02-02 20:01:33,469 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-02+20-01-32+00
2024-02-02 20:01:33,998 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-02+19-28-26+00
2024-02-02 20:31:35,786 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-02+20-31-34+00
2024-02-02 20:31:36,382 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-02+20-01-32+00
2024-02-02 21:01:38,216 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-02+21-01-36+00
2024-02-02 21:01:38,786 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-02+20-31-34+00
2024-02-02 21:04:33,949 - speechbrain.utils.train_logger - INFO - epoch: 12, lr: 9.74e-04, steps: 26364, optimizer: Adam - train loss: 1.48e+02 - valid loss: 17.94, valid ACC: 9.18e-01
2024-02-02 21:04:35,252 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-02+21-04-33+00
2024-02-02 21:04:35,737 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-02+03-34-44+00
2024-02-02 21:04:35,737 - speechbrain.utils.epoch_loop - INFO - Going into epoch 13
2024-02-02 21:34:36,979 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-02+21-34-35+00
2024-02-02 21:34:37,554 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-02+21-01-36+00
2024-02-02 22:04:39,186 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-02+22-04-37+00
2024-02-02 22:04:39,830 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-02+21-34-35+00
2024-02-02 22:34:41,502 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-02+22-34-40+00
2024-02-02 22:34:42,114 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-02+22-04-37+00
2024-02-02 22:37:39,140 - speechbrain.utils.train_logger - INFO - epoch: 13, lr: 9.36e-04, steps: 28561, optimizer: Adam - train loss: 1.45e+02 - valid loss: 17.32, valid ACC: 9.27e-01
2024-02-02 22:37:40,290 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-02+22-37-39+00
2024-02-02 22:37:40,805 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-02+05-07-50+00
2024-02-02 22:37:40,806 - speechbrain.utils.epoch_loop - INFO - Going into epoch 14
2024-02-02 23:07:42,537 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-02+23-07-41+00
2024-02-02 23:07:43,190 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-02+22-34-40+00
2024-02-02 23:37:45,142 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-02+23-37-43+00
2024-02-02 23:37:45,792 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-02+23-07-41+00
2024-02-03 00:07:47,520 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-03+00-07-46+00
2024-02-03 00:07:48,174 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-02+23-37-43+00
2024-02-03 00:10:45,416 - speechbrain.utils.train_logger - INFO - epoch: 14, lr: 9.02e-04, steps: 30758, optimizer: Adam - train loss: 1.44e+02 - valid loss: 17.61, valid ACC: 9.26e-01
2024-02-03 00:10:46,717 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-03+00-10-45+00
2024-02-03 00:10:47,279 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-02+06-40-50+00
2024-02-03 00:10:47,279 - speechbrain.utils.epoch_loop - INFO - Going into epoch 15
2024-02-03 00:40:48,881 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-03+00-40-47+00
2024-02-03 00:40:49,549 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-03+00-07-46+00
2024-02-03 01:10:50,888 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-03+01-10-49+00
2024-02-03 01:10:51,571 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-03+00-40-47+00
2024-02-03 01:40:53,124 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-03+01-40-51+00
2024-02-03 01:40:53,798 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-03+01-10-49+00
2024-02-03 01:43:51,213 - speechbrain.utils.train_logger - INFO - epoch: 15, lr: 8.71e-04, steps: 32955, optimizer: Adam - train loss: 1.42e+02 - valid loss: 17.11, valid ACC: 9.30e-01
2024-02-03 01:43:52,448 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-03+01-43-51+00
2024-02-03 01:43:53,050 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-02+08-18-04+00
2024-02-03 01:43:53,051 - speechbrain.utils.epoch_loop - INFO - Going into epoch 16
2024-02-03 02:13:54,614 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-03+02-13-53+00
2024-02-03 02:13:55,321 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-03+01-40-51+00
2024-02-03 02:43:56,707 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-03+02-43-55+00
2024-02-03 02:43:57,443 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-03+02-13-53+00
2024-02-03 03:13:58,789 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-03+03-13-57+00
2024-02-03 03:13:59,510 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-03+02-43-55+00
2024-02-03 03:17:01,207 - speechbrain.utils.train_logger - INFO - epoch: 16, lr: 8.43e-04, steps: 35152, optimizer: Adam - train loss: 1.40e+02 - valid loss: 16.92, valid ACC: 9.35e-01
2024-02-03 03:17:02,253 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-03+03-17-01+00
2024-02-03 03:17:02,891 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-02+09-51-05+00
2024-02-03 03:17:02,891 - speechbrain.utils.epoch_loop - INFO - Going into epoch 17
2024-02-03 03:47:04,293 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-03+03-47-03+00
2024-02-03 03:47:05,037 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-03+03-13-57+00
2024-02-03 04:17:06,376 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-03+04-17-05+00
2024-02-03 04:17:07,151 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-03+03-47-03+00
2024-02-03 04:47:08,678 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-03+04-47-07+00
2024-02-03 04:47:09,461 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-03+04-17-05+00
2024-02-03 04:50:13,757 - speechbrain.utils.train_logger - INFO - epoch: 17, lr: 8.18e-04, steps: 37349, optimizer: Adam - train loss: 1.39e+02 - valid loss: 16.90, valid ACC: 9.39e-01
2024-02-03 04:50:14,964 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-03+04-50-13+00
2024-02-03 04:50:15,639 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-02+11-24-07+00
2024-02-03 04:50:15,639 - speechbrain.utils.epoch_loop - INFO - Going into epoch 18
2024-02-03 05:20:17,085 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-03+05-20-15+00
2024-02-03 05:20:17,881 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-03+04-47-07+00
2024-02-03 05:50:19,604 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-03+05-50-18+00
2024-02-03 05:50:20,387 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-03+05-20-15+00
2024-02-03 06:20:22,063 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-03+06-20-20+00
2024-02-03 06:20:22,856 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-03+05-50-18+00
2024-02-03 06:23:28,582 - speechbrain.utils.train_logger - INFO - epoch: 18, lr: 7.95e-04, steps: 39546, optimizer: Adam - train loss: 1.38e+02 - valid loss: 16.87, valid ACC: 9.38e-01
2024-02-03 06:23:29,926 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-03+06-23-28+00
2024-02-03 06:23:30,644 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-02+12-57-13+00
2024-02-03 06:23:30,644 - speechbrain.utils.epoch_loop - INFO - Going into epoch 19
2024-02-03 06:53:31,986 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-03+06-53-30+00
2024-02-03 06:53:32,792 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-03+06-20-20+00
2024-02-03 07:23:34,408 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-03+07-23-33+00
2024-02-03 07:23:35,232 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-03+06-53-30+00
2024-02-03 07:53:36,552 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-03+07-53-35+00
2024-02-03 07:53:37,385 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-03+07-23-33+00
2024-02-03 07:56:38,640 - speechbrain.utils.train_logger - INFO - epoch: 19, lr: 7.74e-04, steps: 41743, optimizer: Adam - train loss: 1.37e+02 - valid loss: 17.28, valid ACC: 9.35e-01
2024-02-03 07:56:39,929 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-03+07-56-38+00
2024-02-03 07:56:40,676 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-02+14-30-26+00
2024-02-03 07:56:40,677 - speechbrain.utils.epoch_loop - INFO - Going into epoch 20
2024-02-03 08:26:42,079 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-03+08-26-40+00
2024-02-03 08:26:42,946 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-03+07-53-35+00
2024-02-03 08:56:44,276 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-03+08-56-43+00
2024-02-03 08:56:45,144 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-03+08-26-40+00
2024-02-03 09:26:46,698 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-03+09-26-45+00
2024-02-03 09:26:47,565 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-03+08-56-43+00
2024-02-03 11:25:51,479 - speechbrain.utils.train_logger - INFO - epoch: 20, lr: 7.54e-04, steps: 43940, optimizer: Adam - train loss: 1.35e+02 - valid loss: 16.73, valid ACC: 9.40e-01, valid WER: 7.18
2024-02-03 11:25:52,706 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-03+11-25-51+00
2024-02-03 11:25:53,495 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-02+19-31-30+00
2024-02-03 11:25:53,495 - speechbrain.utils.epoch_loop - INFO - Going into epoch 21
2024-02-03 11:55:55,313 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-03+11-55-54+00
2024-02-03 11:55:56,183 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-03+09-26-45+00
2024-02-03 12:25:57,705 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-03+12-25-56+00
2024-02-03 12:25:58,601 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-03+11-55-54+00
2024-02-03 12:56:00,442 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-03+12-55-59+00
2024-02-03 12:56:01,349 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-03+12-25-56+00
2024-02-03 12:59:04,981 - speechbrain.utils.train_logger - INFO - epoch: 21, lr: 7.36e-04, steps: 46137, optimizer: Adam - train loss: 1.34e+02 - valid loss: 17.16, valid ACC: 9.37e-01
2024-02-03 12:59:06,207 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-03+12-59-04+00
2024-02-03 12:59:07,034 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-02+21-04-33+00
2024-02-03 12:59:07,035 - speechbrain.utils.epoch_loop - INFO - Going into epoch 22
2024-02-03 13:29:08,464 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-03+13-29-07+00
2024-02-03 13:29:09,404 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-03+12-55-59+00
2024-02-03 13:59:10,836 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-03+13-59-09+00
2024-02-03 13:59:11,759 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-03+13-29-07+00
2024-02-03 14:29:13,617 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-03+14-29-12+00
2024-02-03 14:29:14,562 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-03+13-59-09+00
2024-02-03 14:32:12,587 - speechbrain.utils.train_logger - INFO - epoch: 22, lr: 7.19e-04, steps: 48334, optimizer: Adam - train loss: 1.34e+02 - valid loss: 17.44, valid ACC: 9.37e-01
2024-02-03 14:32:13,876 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-03+14-32-12+00
2024-02-03 14:32:14,763 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-02+17-58-20+00
2024-02-03 14:32:14,763 - speechbrain.utils.epoch_loop - INFO - Going into epoch 23
2024-02-03 15:02:16,085 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-03+15-02-14+00
2024-02-03 15:02:17,098 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-03+14-29-12+00
2024-02-03 15:32:18,416 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-03+15-32-17+00
2024-02-03 15:32:19,392 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-03+15-02-14+00
2024-02-03 16:02:20,695 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-03+16-02-19+00
2024-02-03 16:02:21,675 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-03+15-32-17+00
2024-02-03 16:05:28,925 - speechbrain.utils.train_logger - INFO - epoch: 23, lr: 7.03e-04, steps: 50531, optimizer: Adam - train loss: 1.33e+02 - valid loss: 17.35, valid ACC: 9.37e-01
2024-02-03 16:05:30,208 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-03+16-05-28+00
2024-02-03 16:05:31,115 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-03+00-10-45+00
2024-02-03 16:05:31,115 - speechbrain.utils.epoch_loop - INFO - Going into epoch 24
2024-02-03 16:35:32,686 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-03+16-35-31+00
2024-02-03 16:35:33,664 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-03+16-02-19+00
2024-02-03 17:05:35,298 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-03+17-05-34+00
2024-02-03 17:05:36,299 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-03+16-35-31+00
2024-02-03 17:35:38,064 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-03+17-35-36+00
2024-02-03 17:35:39,100 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-03+17-05-34+00
2024-02-03 17:38:35,962 - speechbrain.utils.train_logger - INFO - epoch: 24, lr: 6.89e-04, steps: 52728, optimizer: Adam - train loss: 1.32e+02 - valid loss: 17.19, valid ACC: 9.37e-01
2024-02-03 17:38:37,210 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-03+17-38-35+00
2024-02-03 17:38:38,157 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-02+22-37-39+00
2024-02-03 17:38:38,157 - speechbrain.utils.epoch_loop - INFO - Going into epoch 25
2024-02-03 18:08:40,117 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-03+18-08-38+00
2024-02-03 18:08:41,151 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-03+17-35-36+00
2024-02-03 18:38:42,431 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-03+18-38-41+00
2024-02-03 18:38:43,509 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-03+18-08-38+00
2024-02-03 19:08:45,338 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-03+19-08-44+00
2024-02-03 19:08:46,385 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-03+18-38-41+00
2024-02-03 19:11:51,946 - speechbrain.utils.train_logger - INFO - epoch: 25, lr: 6.75e-04, steps: 54925, optimizer: Adam - train loss: 1.31e+02 - valid loss: 17.28, valid ACC: 9.37e-01
2024-02-03 19:11:53,311 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-03+19-11-51+00
2024-02-03 19:11:54,305 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-03+01-43-51+00
2024-02-03 19:11:54,306 - speechbrain.utils.epoch_loop - INFO - Going into epoch 26
2024-02-03 19:41:55,686 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-03+19-41-54+00
2024-02-03 19:41:56,755 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-03+19-08-44+00
2024-02-03 20:11:58,551 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-03+20-11-57+00
2024-02-03 20:11:59,664 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-03+19-41-54+00
2024-02-03 20:42:01,189 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-03+20-41-59+00
2024-02-03 20:42:02,292 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-03+20-11-57+00
2024-02-03 20:45:04,759 - speechbrain.utils.train_logger - INFO - epoch: 26, lr: 6.62e-04, steps: 57122, optimizer: Adam - train loss: 1.30e+02 - valid loss: 17.31, valid ACC: 9.39e-01
2024-02-03 20:45:05,974 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-03+20-45-04+00
2024-02-03 20:45:07,001 - speechbrain.utils.epoch_loop - INFO - Going into epoch 27
2024-02-03 21:15:08,472 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-03+21-15-07+00
2024-02-03 21:15:09,661 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-03+20-41-59+00
2024-02-03 21:45:10,966 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-03+21-45-09+00
2024-02-03 21:45:12,173 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-03+21-15-07+00
2024-02-03 22:15:13,640 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-03+22-15-12+00
2024-02-03 22:15:14,905 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-03+21-45-09+00
2024-02-03 22:18:15,169 - speechbrain.utils.train_logger - INFO - epoch: 27, lr: 6.49e-04, steps: 59319, optimizer: Adam - train loss: 1.29e+02 - valid loss: 17.29, valid ACC: 9.37e-01
2024-02-03 22:18:16,262 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-03+22-18-15+00
2024-02-03 22:18:17,409 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-03+03-17-01+00
2024-02-03 22:18:17,409 - speechbrain.utils.epoch_loop - INFO - Going into epoch 28
2024-02-03 22:48:19,224 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-03+22-48-17+00
2024-02-03 22:48:20,449 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-03+22-15-12+00
2024-02-03 23:18:22,146 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-03+23-18-20+00
2024-02-03 23:18:23,438 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-03+22-48-17+00
2024-02-03 23:48:25,445 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-03+23-48-23+00
2024-02-03 23:48:26,725 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-03+23-18-20+00
2024-02-03 23:51:25,168 - speechbrain.utils.train_logger - INFO - epoch: 28, lr: 6.37e-04, steps: 61516, optimizer: Adam - train loss: 1.29e+02 - valid loss: 17.29, valid ACC: 9.40e-01
2024-02-03 23:51:26,234 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-03+23-51-25+00
2024-02-03 23:51:27,419 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-03+07-56-38+00
2024-02-03 23:51:27,419 - speechbrain.utils.epoch_loop - INFO - Going into epoch 29
2024-02-04 00:21:29,253 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-04+00-21-27+00
2024-02-04 00:21:30,566 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-03+23-48-23+00
2024-02-04 00:51:32,410 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-04+00-51-31+00
2024-02-04 00:51:33,703 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-04+00-21-27+00
2024-02-04 01:21:34,970 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-04+01-21-33+00
2024-02-04 01:21:36,271 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-04+00-51-31+00
2024-02-04 01:24:42,522 - speechbrain.utils.train_logger - INFO - epoch: 29, lr: 6.26e-04, steps: 63713, optimizer: Adam - train loss: 1.28e+02 - valid loss: 17.68, valid ACC: 9.36e-01
2024-02-04 01:24:43,659 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-04+01-24-42+00
2024-02-04 01:24:44,877 - speechbrain.utils.epoch_loop - INFO - Going into epoch 30
2024-02-04 01:54:46,246 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-04+01-54-45+00
2024-02-04 01:54:47,656 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-04+01-21-33+00
2024-02-04 02:24:49,017 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-04+02-24-47+00
2024-02-04 02:24:50,459 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-04+01-54-45+00
2024-02-04 02:54:52,115 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-04+02-54-50+00
2024-02-04 02:54:53,557 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-04+02-24-47+00
2024-02-04 04:55:02,438 - speechbrain.utils.train_logger - INFO - epoch: 30, lr: 6.16e-04, steps: 65910, optimizer: Adam - train loss: 1.27e+02 - valid loss: 17.12, valid ACC: 9.40e-01, valid WER: 6.89
2024-02-04 04:55:03,601 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-04+04-55-02+00
2024-02-04 04:55:04,965 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-03+12-59-04+00
2024-02-04 04:55:04,966 - speechbrain.utils.epoch_loop - INFO - Going into epoch 31
2024-02-04 05:25:06,315 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-04+05-25-05+00
2024-02-04 05:25:07,785 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-04+02-54-50+00
2024-02-04 05:55:09,461 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-04+05-55-08+00
2024-02-04 05:55:10,936 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-04+05-25-05+00
2024-02-04 06:25:12,521 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-04+06-25-11+00
2024-02-04 06:25:14,022 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-04+05-55-08+00
2024-02-04 06:28:27,798 - speechbrain.utils.train_logger - INFO - epoch: 31, lr: 6.06e-04, steps: 68107, optimizer: Adam - train loss: 1.27e+02 - valid loss: 17.19, valid ACC: 9.41e-01
2024-02-04 06:28:29,086 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-04+06-28-27+00
2024-02-04 06:28:30,515 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-03+14-32-12+00
2024-02-04 06:28:30,516 - speechbrain.utils.epoch_loop - INFO - Going into epoch 32
2024-02-04 06:58:32,161 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-04+06-58-30+00
2024-02-04 06:58:33,668 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-04+06-25-11+00
2024-02-04 07:28:35,244 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-04+07-28-34+00
2024-02-04 07:28:36,650 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-04+06-58-30+00
2024-02-04 07:58:38,037 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-04+07-58-36+00
2024-02-04 07:58:39,463 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-04+07-28-34+00
2024-02-04 08:01:35,188 - speechbrain.utils.train_logger - INFO - epoch: 32, lr: 5.96e-04, steps: 70304, optimizer: Adam - train loss: 1.26e+02 - valid loss: 16.99, valid ACC: 9.42e-01
2024-02-04 08:01:36,365 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-04+08-01-35+00
2024-02-04 08:01:37,846 - speechbrain.utils.epoch_loop - INFO - Going into epoch 33
2024-02-04 08:31:39,683 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-04+08-31-38+00
2024-02-04 08:31:41,212 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-04+07-58-36+00
2024-02-04 09:01:43,624 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-04+09-01-41+00
2024-02-04 09:01:45,737 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-04+08-31-38+00
2024-02-04 09:31:47,451 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-04+09-31-46+00
2024-02-04 09:31:49,027 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-04+09-01-41+00
2024-02-04 09:34:51,717 - speechbrain.utils.train_logger - INFO - epoch: 33, lr: 5.87e-04, steps: 72501, optimizer: Adam - train loss: 1.26e+02 - valid loss: 17.21, valid ACC: 9.39e-01
2024-02-04 09:34:52,966 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-04+09-34-51+00
2024-02-04 09:34:54,587 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-03+16-05-28+00
2024-02-04 09:34:54,590 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-03+17-38-35+00
2024-02-04 09:34:54,590 - speechbrain.utils.epoch_loop - INFO - Going into epoch 34
2024-02-04 10:05:05,168 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-04+10-05-02+00
2024-02-04 10:05:07,453 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-04+09-31-46+00
2024-02-04 10:35:09,164 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-04+10-35-07+00
2024-02-04 10:35:10,668 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-04+10-05-02+00
2024-02-04 11:05:12,151 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-04+11-05-11+00
2024-02-04 11:05:13,757 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-04+10-35-07+00
2024-02-04 11:08:52,374 - speechbrain.utils.train_logger - INFO - epoch: 34, lr: 5.79e-04, steps: 74698, optimizer: Adam - train loss: 1.25e+02 - valid loss: 17.65, valid ACC: 9.38e-01
2024-02-04 11:08:53,615 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-04+11-08-52+00
2024-02-04 11:08:55,177 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-03+19-11-51+00
2024-02-04 11:08:55,178 - speechbrain.utils.epoch_loop - INFO - Going into epoch 35
2024-02-04 11:38:56,780 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-04+11-38-55+00
2024-02-04 11:38:58,389 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-04+11-05-11+00
2024-02-04 12:08:59,659 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-04+12-08-58+00
2024-02-04 12:09:01,295 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-04+11-38-55+00
2024-02-04 12:39:03,069 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-04+12-39-01+00
2024-02-04 12:39:04,673 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-04+12-08-58+00
2024-02-04 12:41:36,047 - speechbrain.utils.train_logger - INFO - epoch: 35, lr: 5.70e-04, steps: 76895, optimizer: Adam - train loss: 1.25e+02 - valid loss: 17.52, valid ACC: 9.38e-01
2024-02-04 12:41:37,321 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-04+12-41-36+00
2024-02-04 12:41:38,926 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-03+06-23-28+00
2024-02-04 12:41:38,926 - speechbrain.utils.epoch_loop - INFO - Going into epoch 36
2024-02-04 13:11:40,634 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-04+13-11-39+00
2024-02-04 13:11:42,353 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-04+12-39-01+00
2024-02-04 13:41:44,151 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-04+13-41-42+00
2024-02-04 13:41:45,850 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-04+13-11-39+00
2024-02-04 14:11:47,220 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-04+14-11-45+00
2024-02-04 14:11:48,957 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-04+13-41-42+00
2024-02-04 14:14:31,833 - speechbrain.utils.train_logger - INFO - epoch: 36, lr: 5.62e-04, steps: 79092, optimizer: Adam - train loss: 1.24e+02 - valid loss: 17.53, valid ACC: 9.38e-01
2024-02-04 14:14:33,114 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-04+14-14-31+00
2024-02-04 14:14:34,752 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-03+22-18-15+00
2024-02-04 14:14:34,752 - speechbrain.utils.epoch_loop - INFO - Going into epoch 37
2024-02-04 14:44:36,063 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-04+14-44-34+00
2024-02-04 14:44:37,825 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-04+14-11-45+00
2024-02-04 15:14:39,240 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-04+15-14-38+00
2024-02-04 15:14:40,965 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-04+14-44-34+00
2024-02-04 15:44:42,203 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-04+15-44-41+00
2024-02-04 15:44:43,923 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-04+15-14-38+00
2024-02-04 15:47:29,478 - speechbrain.utils.train_logger - INFO - epoch: 37, lr: 5.55e-04, steps: 81289, optimizer: Adam - train loss: 1.24e+02 - valid loss: 17.54, valid ACC: 9.39e-01
2024-02-04 15:47:30,716 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-04+15-47-29+00
2024-02-04 15:47:32,400 - speechbrain.utils.epoch_loop - INFO - Going into epoch 38
2024-02-04 16:17:34,070 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-04+16-17-32+00
2024-02-04 16:17:35,921 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-04+15-44-41+00
2024-02-04 16:47:37,513 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-04+16-47-36+00
2024-02-04 16:47:39,449 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-04+16-17-32+00
2024-02-04 17:17:41,210 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-04+17-17-39+00
2024-02-04 17:17:43,084 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-04+16-47-36+00
2024-02-04 17:20:19,846 - speechbrain.utils.train_logger - INFO - epoch: 38, lr: 5.47e-04, steps: 83486, optimizer: Adam - train loss: 1.23e+02 - valid loss: 17.38, valid ACC: 9.41e-01
2024-02-04 17:20:20,985 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-04+17-20-19+00
2024-02-04 17:20:22,854 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-04+01-24-42+00
2024-02-04 17:20:22,855 - speechbrain.utils.epoch_loop - INFO - Going into epoch 39
2024-02-04 17:50:24,424 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-04+17-50-23+00
2024-02-04 17:50:26,327 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-04+17-17-39+00
2024-02-04 18:20:27,840 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-04+18-20-26+00
2024-02-04 18:20:29,809 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-04+17-50-23+00
2024-02-04 18:50:31,366 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-04+18-50-30+00
2024-02-04 18:50:33,287 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-04+18-20-26+00
2024-02-04 18:53:22,904 - speechbrain.utils.train_logger - INFO - epoch: 39, lr: 5.40e-04, steps: 85683, optimizer: Adam - train loss: 1.23e+02 - valid loss: 17.57, valid ACC: 9.37e-01
2024-02-04 18:53:24,177 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-04+18-53-22+00
2024-02-04 18:53:26,084 - speechbrain.utils.epoch_loop - INFO - Going into epoch 40
2024-02-04 19:23:27,339 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-04+19-23-26+00
2024-02-04 19:23:29,488 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-04+18-50-30+00
2024-02-04 19:53:31,093 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-04+19-53-29+00
2024-02-04 19:53:33,214 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-04+19-23-26+00
2024-02-04 20:23:34,600 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-04+20-23-33+00
2024-02-04 20:23:36,725 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-04+19-53-29+00
2024-02-04 22:25:41,097 - speechbrain.utils.train_logger - INFO - epoch: 40, lr: 5.33e-04, steps: 87880, optimizer: Adam - train loss: 1.22e+02 - valid loss: 17.50, valid ACC: 9.39e-01, valid WER: 6.92
2024-02-04 22:25:42,399 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-04+22-25-41+00
2024-02-04 22:25:44,537 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-03+04-50-13+00
2024-02-04 22:25:44,538 - speechbrain.utils.epoch_loop - INFO - Going into epoch 41
2024-02-04 22:55:45,947 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-04+22-55-44+00
2024-02-04 22:55:47,975 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-04+20-23-33+00
2024-02-04 23:25:49,270 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-04+23-25-48+00
2024-02-04 23:25:51,381 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-04+22-55-44+00
2024-02-04 23:55:52,887 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-04+23-55-51+00
2024-02-04 23:55:55,022 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-04+23-25-48+00
2024-02-04 23:58:36,657 - speechbrain.utils.train_logger - INFO - epoch: 41, lr: 5.27e-04, steps: 90077, optimizer: Adam - train loss: 1.22e+02 - valid loss: 17.42, valid ACC: 9.38e-01
2024-02-04 23:58:37,835 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-04+23-58-36+00
2024-02-04 23:58:39,959 - speechbrain.utils.epoch_loop - INFO - Going into epoch 42
2024-02-05 00:28:41,558 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-05+00-28-40+00
2024-02-05 00:28:43,852 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-04+23-55-51+00
2024-02-05 00:58:45,413 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-05+00-58-44+00
2024-02-05 00:58:47,710 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-05+00-28-40+00
2024-02-05 01:28:49,176 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-05+01-28-47+00
2024-02-05 01:28:51,501 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-05+00-58-44+00
2024-02-05 01:31:32,823 - speechbrain.utils.train_logger - INFO - epoch: 42, lr: 5.21e-04, steps: 92274, optimizer: Adam - train loss: 1.21e+02 - valid loss: 17.96, valid ACC: 9.36e-01
2024-02-05 01:31:34,027 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-05+01-31-32+00
2024-02-05 01:31:36,346 - speechbrain.utils.epoch_loop - INFO - Going into epoch 43
2024-02-05 02:01:37,931 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-05+02-01-36+00
2024-02-05 02:01:40,438 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-05+01-28-47+00
2024-02-05 02:31:42,035 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-05+02-31-40+00
2024-02-05 02:31:44,551 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-05+02-01-36+00
2024-02-05 03:01:46,444 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-05+03-01-45+00
2024-02-05 03:01:49,020 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-05+02-31-40+00
2024-02-05 03:04:32,562 - speechbrain.utils.train_logger - INFO - epoch: 43, lr: 5.14e-04, steps: 94471, optimizer: Adam - train loss: 1.21e+02 - valid loss: 17.70, valid ACC: 9.38e-01
2024-02-05 03:04:33,867 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-05+03-04-32+00
2024-02-05 03:04:36,402 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-04+11-08-52+00
2024-02-05 03:04:36,408 - speechbrain.utils.epoch_loop - INFO - Going into epoch 44
2024-02-05 03:34:38,186 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-05+03-34-36+00
2024-02-05 03:34:40,748 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-05+03-01-45+00
2024-02-05 04:04:42,494 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-05+04-04-41+00
2024-02-05 04:04:45,046 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-05+03-34-36+00
2024-02-05 04:34:46,758 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-05+04-34-45+00
2024-02-05 04:34:49,326 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-05+04-04-41+00
2024-02-05 04:37:16,919 - speechbrain.utils.train_logger - INFO - epoch: 44, lr: 5.09e-04, steps: 96668, optimizer: Adam - train loss: 1.21e+02 - valid loss: 17.39, valid ACC: 9.38e-01
2024-02-05 04:37:18,224 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-05+04-37-16+00
2024-02-05 04:37:20,783 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-04+12-41-36+00
2024-02-05 04:37:20,783 - speechbrain.utils.epoch_loop - INFO - Going into epoch 45
2024-02-05 05:07:22,419 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-05+05-07-21+00
2024-02-05 05:07:25,032 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-05+04-34-45+00
2024-02-05 05:37:26,308 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-05+05-37-25+00
2024-02-05 05:37:28,951 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-05+05-07-21+00
2024-02-05 06:07:30,176 - speechbrain.utils.checkpoints - DEBUG - Saved an intra-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-05+06-07-29+00
2024-02-05 06:07:32,806 - speechbrain.utils.checkpoints - DEBUG - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-05+05-37-25+00
2024-02-05 06:10:22,261 - speechbrain.utils.train_logger - INFO - epoch: 45, lr: 5.03e-04, steps: 98865, optimizer: Adam - train loss: 1.20e+02 - valid loss: 17.80, valid ACC: 9.37e-01
2024-02-05 06:10:23,547 - speechbrain.utils.checkpoints - INFO - Saved an end-of-epoch checkpoint in results/transformer/74443/save/CKPT+2024-02-05+06-10-22+00
2024-02-05 06:10:26,206 - speechbrain.utils.checkpoints - INFO - Deleted checkpoint in results/transformer/74443/save/CKPT+2024-02-04+14-14-31+00
2024-02-05 06:10:26,206 - speechbrain.utils.epoch_loop - INFO - Going into epoch 46
